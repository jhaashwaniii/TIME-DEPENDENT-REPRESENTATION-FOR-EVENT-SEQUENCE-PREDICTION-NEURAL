{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS726-AML-Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkeaFhs47KFM",
        "outputId": "532c345c-b586-4048-e049-fc96b10ec0ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfS7TE5u7NfC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQUtTEQ9qm4"
      },
      "source": [
        "from keras import Input\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import LSTM\n",
        "from sklearn.utils import class_weight\n",
        "from keras.layers import Flatten\n",
        "from keras.initializers import Constant\n",
        "from keras.models import model_from_json\n",
        "import tensorflow as tf\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "import torch.nn.functional as F\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zazc5QLygTUt",
        "outputId": "f7c8599f-ea4c-4f25-c5c8-4161611dd7d2"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2y32mUm9rV1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5btVTg4QWw_"
      },
      "source": [
        "## Preprocessing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LorUwdG4-PvL"
      },
      "source": [
        "def get_data(file_name , phase = 'train' , type = 'event'): # phase -(train ,test) , type - (event , time)\n",
        "\n",
        "  df=pd.read_csv(file_name,header=None)\n",
        "\n",
        "  X , y =[] ,[]\n",
        "\n",
        "  for i in range(len(df[0])):\n",
        "\n",
        "    data = df[0][i].split(' ')[:-1]\n",
        "\n",
        "    if (type == 'time'):\n",
        "      data = [log(float(elem)+1,10) for elem in data]\n",
        "    else:\n",
        "      data = [int(elem) for elem in data]\n",
        "\n",
        "    if( len(data) > 1):\n",
        "\n",
        "      if(phase == 'train'):\n",
        "\n",
        "        #for j in range(1,len(data)):\n",
        "        X.append(data[:-1])\n",
        "        y.append(data[-1])\n",
        "\n",
        "      else:\n",
        "\n",
        "        X.append(data[:-1])\n",
        "        y.append(data[-1])\n",
        "\n",
        "  print(phase , type , len(X) ,len(y))\n",
        "  return X , y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HiH6BwR9cWp"
      },
      "source": [
        "vocab=[str(i) for i in range(0,23)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUJfpbFXMxoQ"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPzO4plcMzFn"
      },
      "source": [
        "class MimicDataset(Dataset):\n",
        "\n",
        "    def __init__(self, E, Y_e, T, Y_t):\n",
        "        self.E = E\n",
        "        self.Y_e = Y_e\n",
        "        self.T = T\n",
        "        self.Y_t = Y_t\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.Y_e)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if (self.T is not None):\n",
        "\n",
        "          if (self.Y_t is not None):\n",
        "            return torch.from_numpy(self.E[idx]), torch.tensor(self.Y_e[idx]), torch.tensor(self.T[idx]).float(), torch.tensor(self.Y_t[idx])\n",
        "          else:\n",
        "            return torch.from_numpy(self.E[idx]), torch.tensor(self.Y_e[idx]), torch.tensor(self.T[idx]).float(), torch.tensor([0])\n",
        "\n",
        "        else:\n",
        "            return torch.from_numpy(self.E[idx]), torch.tensor(self.Y_e[idx]) , torch.tensor([0]), torch.tensor([0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb86FabBWuDQ"
      },
      "source": [
        "def get_data_loader(X,Y_e,T=None,Y_t=None,batch_size=32):\n",
        "\n",
        "  if T is not None:\n",
        "\n",
        "    if Y_t is not None:\n",
        "      dataset = MimicDataset(np.array(X), np.array(Y_e),np.array(T),np.array(Y_t))\n",
        "      data_loader = DataLoader(dataset, batch_size)\n",
        "    else:\n",
        "      dataset = MimicDataset(np.array(X), np.array(Y_e),np.array(T),None)\n",
        "      data_loader = DataLoader(dataset, batch_size)\n",
        "\n",
        "  else:\n",
        "    dataset = MimicDataset(np.array(X), np.array(Y_e),None,None)\n",
        "    data_loader = DataLoader(dataset, batch_size)\n",
        "\n",
        "  return data_loader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DawlodW8FGTQ"
      },
      "source": [
        "def Data_Loader(files): #[train_event , test_event , train_time , test_time]\n",
        "\n",
        "  X_event_train , y_event_train = get_data(files[0] , 'train' , 'event')\n",
        "  X_event_test , y_event_test = get_data(files[1] , 'test' ,'event')\n",
        "\n",
        "  X_time_train , y_time_train = get_data(files[2] , 'train' ,'time')\n",
        "  X_time_test , y_time_test = get_data(files[3] , 'test', 'time')\n",
        "\n",
        "  \n",
        "  max_len=max([len(i) for i in X_event_train])\n",
        "\n",
        "\n",
        "  X_event_train = sequence.pad_sequences(X_event_train , maxlen=max_len,padding=\"pre\")\n",
        "  X_time_train = sequence.pad_sequences(X_time_train , maxlen=max_len,padding=\"pre\")\n",
        "\n",
        "  Y_event_train = y_event_train\n",
        "  Y_time_train = y_time_train\n",
        "\n",
        "  X_event_test = sequence.pad_sequences(X_event_test, maxlen=max_len,padding=\"pre\")\n",
        "  X_time_test = sequence.pad_sequences(X_time_test, maxlen=max_len,padding=\"pre\")\n",
        "\n",
        "  y_event_test = y_event_test\n",
        "  y_time_test = y_time_test\n",
        "\n",
        "  train_loader = get_data_loader(X_event_train , y_event_train , X_time_train , y_time_train)\n",
        "  test_loader = get_data_loader(X_event_test , y_event_test , X_time_test , y_time_test)\n",
        "\n",
        "  return (train_loader , test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqXmL6-qcLhI"
      },
      "source": [
        "## Attention Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G2SdBTPcLBP"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, heads):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_size // heads\n",
        "\n",
        "        assert (\n",
        "            self.head_dim * heads == embed_size\n",
        "        ), \"Embedding size needs to be divisible by heads\"\n",
        "\n",
        "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
        "\n",
        "    def forward(self, values, keys, query, mask):\n",
        "        # Get number of training examples\n",
        "        N = query.shape[0]\n",
        "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
        "        # Split the embedding into self.heads different pieces\n",
        "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
        "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
        "        query = query.reshape(N, query_len, self.heads, self.head_dim)\n",
        "        values = self.values(values)  # (N, value_len, heads, head_dim)\n",
        "        keys = self.keys(keys)  # (N, key_len, heads, head_dim)\n",
        "        queries = self.queries(query)  # (N, query_len, heads, heads_dim)\n",
        "\n",
        "        # Einsum does matrix mult. for query*keys for each training example\n",
        "        # with every other training example, don't be confused by einsum\n",
        "        # it's just how I like doing matrix multiplication & bmm\n",
        "\n",
        "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
        "        # queries shape: (N, query_len, heads, heads_dim),\n",
        "        # keys shape: (N, key_len, heads, heads_dim)\n",
        "        # energy: (N, heads, query_len, key_len)\n",
        "\n",
        "        # Mask padded indices so their weights become 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "        # Normalize energy values similarly to seq2seq + attention\n",
        "        # so that they sum to 1. Also divide by scaling factor for\n",
        "        # better stability\n",
        "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
        "        # attention shape: (N, heads, query_len, key_len)\n",
        "\n",
        "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
        "            N, query_len, self.heads * self.head_dim\n",
        "        )\n",
        "        # attention shape: (N, heads, query_len, key_len)\n",
        "        # values shape: (N, value_len, heads, heads_dim)\n",
        "        # out after matrix multiply: (N, query_len, heads, head_dim), then\n",
        "        # we reshape and flatten the last two dimensions.\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        # Linear layer doesn't modify the shape, final shape will be\n",
        "        # (N, query_len, embed_size)\n",
        "\n",
        "        return out\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = SelfAttention(embed_size, heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, value, key, query, mask=None):\n",
        "        attention = self.attention(value, key, query, mask)\n",
        "\n",
        "        # Add skip connection, run through normalization and finally dropout\n",
        "        x = self.dropout(self.norm1(attention + query))\n",
        "        forward = self.feed_forward(x)\n",
        "        out = self.dropout(self.norm2(forward + x))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3jZLGcI9ja0"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7vFJ40FcREc"
      },
      "source": [
        "class Model_Attention(torch.nn.Module):\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    #self.embedding_time=nn.Embedding(3,embedding_dim)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,204)\n",
        "    self.linear_emb=nn.Linear(3,embedding_dim)\n",
        "    self.linear_proj=nn.Linear(1,3)\n",
        "    self.linear_duration_proj=nn.Linear(hidden_dim,1)\n",
        "    self.linear_cat=nn.Linear(2*embedding_dim,embedding_dim)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.softmax=nn.Softmax(dim=2)\n",
        "\n",
        "    self.norm_event= nn.LayerNorm(embedding_dim)\n",
        "    self.transformer_block_time= TransformerBlock(embed_size=embedding_dim, heads=1, dropout=0.5, forward_expansion=1)\n",
        "    self.transformer_block_event= TransformerBlock(embed_size=embedding_dim, heads=1, dropout=0.5, forward_expansion=1)\n",
        "    self.transformer_block_cross= TransformerBlock(embed_size=embedding_dim, heads=1, dropout=0.5, forward_expansion=1)\n",
        "\n",
        "  def forward(self,event,event_time):\n",
        "    event_time = event_time.unsqueeze(-1)\n",
        "    event_embedding=self.embedding(event)\n",
        "    #print(event_embedding)\n",
        "    #print()\n",
        "    projection_embedding=self.linear_proj(event_time)\n",
        "    #print(projection_embedding)\n",
        "    #print()\n",
        "    soft_embedding=self.softmax(projection_embedding)\n",
        "    #mask_embedding=self.linear_mask(ctx_embedding)\n",
        "    #print(mask_embedding)\n",
        "    \n",
        "    #print()\n",
        "    time_embedding=self.linear_emb(soft_embedding)\n",
        "\n",
        "    time_attention=self.transformer_block_time(time_embedding,time_embedding,time_embedding)\n",
        "\n",
        "    # Self Attention Event Embedding\n",
        "\n",
        "    event_attention=self.transformer_block_event(event_embedding,event_embedding,event_embedding)\n",
        "\n",
        "    # Cross Attention\n",
        "\n",
        "    input_lstm=self.transformer_block_cross(time_attention,time_attention,event_attention)\n",
        "\n",
        "    input_lstm=self.norm_event(input_lstm+event_embedding)\n",
        "\n",
        "    lstm_out,(ht,ct)=self.lstm(input_lstm)\n",
        "\n",
        "    #print(\"After LSTM Layer\")\n",
        "    output1=self.linear(ht[-1])\n",
        "    output2=self.linear_duration_proj(ht[-1])\n",
        "    return (output1,output2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4pZ5UlQm2HB"
      },
      "source": [
        "class Model_TimeContext(torch.nn.Module):\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,len(vocab))\n",
        "    self.linear_ctx=nn.Linear(1,1)\n",
        "    self.linear_mask=nn.Linear(1,embedding_dim) #(1,embedding dim)\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "  def forward(self,event,event_time):\n",
        "    event_time = event_time.unsqueeze(-1)\n",
        "    #print(event.shape , event_time.shape)\n",
        "    event_embedding=self.embedding(event)\n",
        "    #print(event_embedding.shape)\n",
        "    ctx_embedding=self.linear_ctx(event_time)\n",
        "    #print(ctx_embedding.shape)\n",
        "    ctx_embedding=self.relu(ctx_embedding)\n",
        "    #print(ctx_embedding.shape)\n",
        "    mask_embedding=self.linear_mask(ctx_embedding)\n",
        "    #print(mask_embedding.shape)\n",
        "    mask_embedding_sig=torch.sigmoid(mask_embedding)\n",
        "    #print(event_embedding.shape , mask_embedding_sig.shape)\n",
        "    input_lstm=torch.mul(event_embedding,mask_embedding_sig)\n",
        "    #print(input_lstm.shape)\n",
        "    lstm_out,(ht,ct)=self.lstm(input_lstm)\n",
        "    #print(\"After LSTM Layer\")\n",
        "    output=self.linear(ht[-1])\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lRaP6vbAALc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF0Ds2AIYg1W"
      },
      "source": [
        "class Model_TimeConcat(torch.nn.Module):\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    self.lstm=nn.LSTM(embedding_dim+1,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,len(vocab))\n",
        "\n",
        "  def forward(self,event,event_time):\n",
        "    event_embedding=self.embedding(event)\n",
        "    event_time = event_time.unsqueeze(-1)\n",
        "    input_lstm=torch.cat((event_embedding,event_time),2)\n",
        "    #print(input_lstm.shape)\n",
        "    lstm_out,(ht,ct)=self.lstm(input_lstm)\n",
        "    #print(\"After LSTM Layer\")\n",
        "    output=self.linear(ht[-1])\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_p_RKSbNFKL"
      },
      "source": [
        "class Model_NoTime(torch.nn.Module):\n",
        "\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "\n",
        "    super().__init__()\n",
        "    self.embedding_event=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,len(vocab))\n",
        "    self.linear1=nn.Linear(embedding_dim,7)\n",
        "\n",
        "  def forward(self,x):\n",
        "    #print(x)\n",
        "    x=self.embedding_event(x)\n",
        "    #x=self.linear1(x)\n",
        "    #print('after_linear')\n",
        "    lstm_out, (ht, ct)=self.lstm(x)\n",
        "    x=self.linear(ht[-1])\n",
        "    #print(lstm_out.shape)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba0WZyhnABIP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv29OXDypHEF"
      },
      "source": [
        "class Model_TimeJoint(torch.nn.Module):\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    #self.embedding_time=nn.Embedding(3,embedding_dim)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,len(vocab))\n",
        "    self.linear_emb=nn.Linear(3,embedding_dim)\n",
        "    self.linear_proj=nn.Linear(1,3)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.softmax=nn.Softmax(dim=2)\n",
        "\n",
        "  def forward(self,event,event_time):\n",
        "    event_time = event_time.unsqueeze(-1)\n",
        "    event_embedding=self.embedding(event)\n",
        "    #print(event_embedding)\n",
        "    #print()\n",
        "    projection_embedding=self.linear_proj(event_time)\n",
        "    #print(projection_embedding)\n",
        "    #print()\n",
        "    soft_embedding=self.softmax(projection_embedding)\n",
        "    #mask_embedding=self.linear_mask(ctx_embedding)\n",
        "    #print(mask_embedding)\n",
        "    \n",
        "    #print()\n",
        "    time_embedding=self.linear_emb(soft_embedding)\n",
        "    #print(time_embedding)\n",
        "    input_lstm=(event_embedding+time_embedding)/2\n",
        "    #print()\n",
        "    #print(mask_embedding_sig\n",
        "    #print(input_lstm)\n",
        "    #print()\n",
        "    lstm_out,(ht,ct)=self.lstm(input_lstm)\n",
        "    #print(\"After LSTM Layer\")\n",
        "    output=self.linear(ht[-1])\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hSR90SABt7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQMybkj5uuBc"
      },
      "source": [
        "class Model_TimeJointRegularized(torch.nn.Module):\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    #self.embedding_time=nn.Embedding(3,embedding_dim)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,len(vocab))\n",
        "    self.linear_emb=nn.Linear(3,embedding_dim)\n",
        "    self.linear_proj=nn.Linear(1,3)\n",
        "    self.linear_duration_proj=nn.Linear(hidden_dim,1)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.softmax=nn.Softmax(dim=2)\n",
        "\n",
        "  def forward(self,event,event_time):\n",
        "    event_time = event_time.unsqueeze(-1)\n",
        "    event_embedding=self.embedding(event)\n",
        "    #print(event_embedding)\n",
        "    #print()\n",
        "    projection_embedding=self.linear_proj(event_time)\n",
        "    #print(projection_embedding)\n",
        "    #print()\n",
        "    soft_embedding=self.softmax(projection_embedding)\n",
        "    #mask_embedding=self.linear_mask(ctx_embedding)\n",
        "    #print(mask_embedding)\n",
        "    \n",
        "    #print()\n",
        "    time_embedding=self.linear_emb(soft_embedding)\n",
        "    #print(time_embedding)\n",
        "    input_lstm=(event_embedding+time_embedding)/2\n",
        "    #print()\n",
        "    #print(mask_embedding_sig\n",
        "    #print(input_lstm)\n",
        "    #print()\n",
        "    lstm_out,(ht,ct)=self.lstm(input_lstm)\n",
        "\n",
        "    #print(\"After LSTM Layer\")\n",
        "    output1=self.linear(ht[-1])\n",
        "    output2=self.linear_duration_proj(ht[-1])\n",
        "    return (output1,output2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iAIbRwjACWX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y5qx3rgACvj"
      },
      "source": [
        "class Model_TimeContextRegularized(torch.nn.Module):\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim , len(vocab))\n",
        "    self.linear_ctx=nn.Linear(1,1)\n",
        "    self.linear_proj=nn.Linear(1,3)\n",
        "    self.linear_mask=nn.Linear(1,embedding_dim) #(1,embedding dim)\n",
        "    self.linear_duration_proj=nn.Linear(hidden_dim,1)\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "  def forward(self,event,event_time):\n",
        "    event_time = event_time.unsqueeze(-1)\n",
        "    #print(event.shape , event_time.shape)\n",
        "    event_embedding=self.embedding(event)\n",
        "    #print(event_embedding.shape)\n",
        "    ctx_embedding=self.linear_ctx(event_time)\n",
        "    #print(ctx_embedding.shape)\n",
        "    ctx_embedding=self.relu(ctx_embedding)\n",
        "    #print(ctx_embedding.shape)\n",
        "    mask_embedding=self.linear_mask(ctx_embedding)\n",
        "    #print(mask_embedding.shape)\n",
        "    mask_embedding_sig=torch.sigmoid(mask_embedding)\n",
        "    #print(event_embedding.shape , mask_embedding_sig.shape)\n",
        "    input_lstm=torch.mul(event_embedding,mask_embedding_sig)\n",
        "    #print(input_lstm.shape)\n",
        "    lstm_out,(ht,ct)=self.lstm(input_lstm)\n",
        "    #print(\"After LSTM Layer\")\n",
        "    output1=self.linear(ht[-1])\n",
        "    output2=self.linear_duration_proj(ht[-1])\n",
        "    return (output1,output2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3tB-NgyT58g"
      },
      "source": [
        "class Model_FeedForward(torch.nn.Module):\n",
        "  def __init__(self,vocab,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(len(vocab),embedding_dim,padding_idx=0)\n",
        "    #self.embedding_time=nn.Embedding(3,embedding_dim)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "    self.linear=nn.Linear(hidden_dim,204)\n",
        "    self.linear_emb=nn.Linear(3,embedding_dim)\n",
        "    self.linear_proj=nn.Linear(1,3)\n",
        "    self.linear_duration_proj=nn.Linear(hidden_dim,1)\n",
        "    self.linear_cat=nn.Linear(2*embedding_dim,embedding_dim)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.softmax=nn.Softmax(dim=2)\n",
        "\n",
        "  def forward(self,event,event_time):\n",
        "    event_time = event_time.unsqueeze(-1)\n",
        "    event_embedding=self.embedding(event)\n",
        "    #print(event_embedding)\n",
        "    #print()\n",
        "    projection_embedding=self.linear_proj(event_time)\n",
        "    #print(projection_embedding)\n",
        "    #print()\n",
        "    soft_embedding=self.softmax(projection_embedding)\n",
        "    #mask_embedding=self.linear_mask(ctx_embedding)\n",
        "    #print(mask_embedding)\n",
        "    \n",
        "    #print()\n",
        "    time_embedding=self.linear_emb(soft_embedding)\n",
        "\n",
        "    input_lstm=torch.cat((event_embedding,time_embedding),2)\n",
        "\n",
        "    input_lstm=self.linear_cat(input_lstm)\n",
        "    lstm_out,(ht,ct)=self.lstm(input_lstm)\n",
        "\n",
        "    #print(\"After LSTM Layer\")\n",
        "    output1=self.linear(ht[-1])\n",
        "    output2=self.linear_duration_proj(ht[-1])\n",
        "    return (output1,output2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PRql9mgADXD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRwMO4HzYvcE"
      },
      "source": [
        "def get_model(type, vocab, embedding_dim, hidden_dim):\n",
        "\n",
        "  if(type == 'NoTime'):\n",
        "    model = Model_NoTime(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  if(type == 'TimeConcat'):\n",
        "    model = Model_TimeConcat(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  if(type == 'TimeContext'):\n",
        "    model = Model_TimeContext(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  if(type == 'TimeJoint'):\n",
        "    model = Model_TimeJoint(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  if(type == 'TimeJointRegularized'):\n",
        "    model = Model_TimeJointRegularized(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  if(type == 'TimeContextRegularized'):\n",
        "    model = Model_TimeContextRegularized(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  if(type == 'FeedForward'):\n",
        "    model = Model_FeedForward(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  if(type == 'Attention'):\n",
        "    model = Model_Attention(vocab,embedding_dim,hidden_dim)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_frbFQ_OlvhQ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlR6_EPMvWdJ"
      },
      "source": [
        "def cross_entropy_duration(pred, soft_targets):\n",
        "    #print(pred.shape , soft_targets.shape)\n",
        "    logsoftmax = nn.LogSoftmax(dim=1)\n",
        "    return torch.sum(- soft_targets * logsoftmax(pred), 1).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5J3jsjBvXaA"
      },
      "source": [
        "variance_train_data = torch.tensor(1.0,requires_grad=True) # need to be calculated...\n",
        "\n",
        "def duration_regularization(pred , target):\n",
        "\n",
        "  target = target.unsqueeze(-1)\n",
        "  return torch.div((pred - target)**2 , 2* (variance_train_data**2)).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SieQ2NacOSgl"
      },
      "source": [
        "def train_model(model,train_data_loader,test_data_loader , model_type,regularization = None , epochs=2,lr=0.001):\n",
        "\n",
        "  model.to(device)\n",
        "  parameters=filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "\n",
        "  train_accuracy , train_loss , test_accuracy , test_loss = 0.0 , 0.0 , 0.0 ,0.0\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(epochs):\n",
        "    correct=0\n",
        "    total=0\n",
        "    model.train()\n",
        "\n",
        "    sum_loss=0.0\n",
        "\n",
        "    for e,y_e,t,y_t in train_data_loader:\n",
        "      \n",
        "      loss = 0.0\n",
        "      #print(x.shape , y.shape , t.shape)\n",
        "      e = e.to(device)\n",
        "      y_e = y_e.to(device)\n",
        "      t = t.to(device)\n",
        "      y_t = y_t.to(device)\n",
        "\n",
        "      if ( model_type == 'NoTime'):\n",
        "        y_e_pred = model(e)\n",
        "      elif (model_type == 'TimeContextRegularized' or model_type == 'TimeJointRegularized' or model_type == 'FeedForward' or model_type == 'Attention'):  \n",
        "        y_e_pred , y_t_pred = model(e,t)\n",
        "      else:\n",
        "        y_e_pred = model(e,t)\n",
        "\n",
        "      if ( regularization == 'cross_entropy'):\n",
        "\n",
        "        duration_embedding_pred = model.linear_proj(y_t_pred)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          duration_embedding_true=model.linear_proj(y_t.unsqueeze(-1).type(torch.cuda.FloatTensor))\n",
        "          softmax = nn.Softmax(dim=1)\n",
        "          soft_duration_embedding_true=softmax(duration_embedding_true)\n",
        "\n",
        "        loss += cross_entropy_duration(duration_embedding_pred,soft_duration_embedding_true)\n",
        "\n",
        "      if ( regularization == 'nll'):\n",
        "\n",
        "        loss += duration_regularization(y_t_pred,y_t)\n",
        "     \n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      l = F.cross_entropy(y_e_pred, y_e)\n",
        "      loss += l\n",
        "      #print(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      pred = torch.max(y_e_pred, 1)[1]\n",
        "      #print(pred)\n",
        "      correct += (pred== y_e).float().sum()\n",
        "      total+=y_e.shape[0]\n",
        "      sum_loss += loss.item()*y_e.shape[0]\n",
        "\n",
        "    train_accuracy += correct/total\n",
        "    train_loss += sum_loss/total\n",
        "\n",
        "    #if(i%20==0):\n",
        "     # print(i,\"th Epoch, Train Accuracy=\",(correct/total),\"Train_loss=\",(sum_loss/total))\n",
        "\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    correct=0\n",
        "    total=0\n",
        "  \n",
        "    sum_loss=0.0\n",
        "\n",
        "    r5t , r10t ,r20t = 0,0,0\n",
        "\n",
        "    for e,y_e,t,y_t in test_data_loader:\n",
        "      \n",
        "      loss = 0.0\n",
        "      #print(x.shape , y.shape , t.shape)\n",
        "      e = e.to(device)\n",
        "      y_e = y_e.to(device)\n",
        "      t = t.to(device)\n",
        "      y_t = y_t.to(device)\n",
        "\n",
        "      if ( model_type == 'NoTime'):\n",
        "        y_e_pred = model(e)\n",
        "      elif (model_type == 'TimeContextRegularized' or model_type == 'TimeJointRegularized' or model_type == 'FeedForward' or model_type == 'Attention'):  \n",
        "        y_e_pred , y_t_pred = model(e,t)\n",
        "      else:\n",
        "        y_e_pred = model(e,t)\n",
        "\n",
        "      if ( regularization == 'cross_entropy'):\n",
        "\n",
        "        duration_embedding_pred = model.linear_proj(y_t_pred)\n",
        "\n",
        "        \n",
        "        duration_embedding_true=model.linear_proj(y_t.unsqueeze(-1).type(torch.cuda.FloatTensor))\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        soft_duration_embedding_true=softmax(duration_embedding_true)\n",
        "\n",
        "        loss += cross_entropy_duration(duration_embedding_pred,soft_duration_embedding_true)\n",
        "\n",
        "      if ( regularization == 'nll'):\n",
        "\n",
        "        loss += duration_regularization(y_t_pred,y_t)\n",
        "    \n",
        "      l = F.cross_entropy(y_e_pred, y_e)\n",
        "      loss += l\n",
        "      pred = torch.max(y_e_pred, 1)[1]\n",
        "    \n",
        "   \n",
        "      correct += (pred== y_e).float().sum()\n",
        "      total+=y_e.shape[0]\n",
        "      sum_loss += loss.item()*y_e.shape[0]\n",
        "    \n",
        "    #print(\"Test Accuracy=\",(correct/total),\"Test_loss=\",(sum_loss/total))\n",
        "    test_accuracy += correct/total\n",
        "    test_loss += sum_loss/total\n",
        "\n",
        "    return (train_accuracy/epochs , train_loss/epochs , test_accuracy , test_loss)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "-w3V7xLJK3E7",
        "outputId": "765ea41d-a768-41f6-848f-2388a2d33434"
      },
      "source": [
        "models = ['NoTime','TimeConcat','TimeJoint','TimeContext','TimeJointRegularized','TimeContextRegularized','FeedForward','Attention']\n",
        "regularization = ['cross_entropy' , 'nll']\n",
        "\n",
        "for model_type in models:\n",
        "\n",
        "  regul = None\n",
        "  if model_type == 'TimeJointRegularized' or model_type == 'TimeContextRegularized' or model_type == 'FeedForward' or model_type == 'Attention':\n",
        "    regul = 'cross_entropy'\n",
        "\n",
        "  total_train_acc , total_train_loss , total_test_acc , total_test_loss = [] ,[],[] ,[]\n",
        "\n",
        "  for i in range(1,6):\n",
        "\n",
        "    files = []\n",
        "    root_path = '/content/drive/MyDrive/so/'\n",
        "    files.append(root_path + 'event-' + str(i) + '-train.txt')\n",
        "    files.append(root_path + 'event-' + str(i) + '-test.txt')\n",
        "    files.append(root_path + 'time-' + str(i) + '-train.txt')\n",
        "    files.append(root_path + 'time-' + str(i) + '-test.txt')\n",
        "    \n",
        "    model  = get_model(type = model_type , vocab = vocab , embedding_dim= 5 , hidden_dim = 10)\n",
        "    train_loader , test_loader = Data_Loader(files) \n",
        "    train_acc , train_loss , test_acc , test_loss = train_model(model = model, train_data_loader = train_loader, test_data_loader = test_loader , model_type = model_type, regularization=regul, epochs=100, lr=0.001)\n",
        "\n",
        "    total_train_acc.append(train_acc)\n",
        "    total_train_loss.append(train_loss)\n",
        "    total_test_acc.append(test_acc)\n",
        "    total_test_loss.append(test_loss)\n",
        "\n",
        "  best_index = np.argmax(total_test_acc)\n",
        "  print('Model : {} ,Regularization : {} '.format(model_type , regul))\n",
        "  print('Train Accuracy : {}'.format(total_train_acc[best_index]))\n",
        "  print('Train Loss : {}'.format(total_train_loss[best_index]))\n",
        "  print('Test Accuracy : {}'.format(total_test_acc[best_index]))\n",
        "  print('Test Loss : {}'.format(total_test_loss[best_index]))\n",
        "  print('*******************************************************************************************')\n",
        "  print('*******************************************************************************************')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train event 5307 5307\n",
            "test event 1326 1326\n",
            "train time 5307 5307\n",
            "test time 1326 1326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-184-0bc318b1e57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_Loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtotal_train_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-182-4d4fb01f745d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data_loader, test_data_loader, model_type, regularization, epochs, lr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregularization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylNZdx3HPs61"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjogf7xvK28J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}